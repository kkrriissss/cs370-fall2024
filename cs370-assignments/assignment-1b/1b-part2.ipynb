{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTlbDUWthrLb"
      },
      "source": [
        "# Kriss Sitapara Assignment 1B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "byFiit7bwd7q"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load the datasel, I moved the kaggle.json file from the api into this and downloaded the dataset that way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1LzbFHh3cI"
      },
      "source": [
        "# Optimization algorithms for linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9EmlM7RiUX3"
      },
      "source": [
        "# Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bGNSt8DvZaM"
      },
      "source": [
        "**______________________________________________________________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyNeqkywvvNg"
      },
      "source": [
        "**Task 1: Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orgdDXBsvwDL"
      },
      "source": [
        "**______________________________________________________________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbtwj1DigYaZ",
        "outputId": "6190e2c1-396c-464b-de9c-8f881b47eb64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Downloading avazu-ctr-prediction.zip to /content\n",
            " 99% 1.18G/1.19G [00:09<00:00, 238MB/s]\n",
            "100% 1.19G/1.19G [00:09<00:00, 140MB/s]\n",
            "Archive:  avazu-ctr-prediction.zip\n",
            "  inflating: /content/sampleSubmission.gz  \n",
            "  inflating: /content/test.gz        \n",
            "  inflating: /content/train.gz       \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c avazu-ctr-prediction\n",
        "!unzip avazu-ctr-prediction.zip -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Qs5efO1hgrgk"
      },
      "outputs": [],
      "source": [
        "#loading data\n",
        "def load_data(n_rows=100_000):\n",
        "    chunksize = 10 ** 6\n",
        "    filename = '/content/train.gz'\n",
        "    chunks = []\n",
        "\n",
        "    with pd.read_csv(filename, chunksize=chunksize, compression='gzip', nrows=n_rows) as reader:\n",
        "        for chunk in reader:\n",
        "            chunks.append(chunk)\n",
        "    data = pd.concat(chunks)\n",
        "    return data\n",
        "\n",
        "data = load_data(300_000)\n",
        "data_train = data.sample(10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Y3pQN4G4jOqt"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "def preprocess_data(data):\n",
        "    data = data.drop(columns=['id', 'device_id', 'device_ip', 'site_id', 'site_domain', 'app_id', 'app_domain'])\n",
        "    data = data.dropna()\n",
        "\n",
        "    selected_features = ['click', 'hour', 'banner_pos', 'site_category', 'app_category',\n",
        "                         'device_type', 'device_conn_type']\n",
        "    data = data[selected_features]\n",
        "    data_encoded = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "    if 'hour' in data_encoded.columns:\n",
        "        hour_mean = data_encoded['hour'].mean()\n",
        "        hour_std = data_encoded['hour'].std()\n",
        "        data_encoded['hour'] = (data_encoded['hour'] - hour_mean) / hour_std\n",
        "\n",
        "    return data_encoded\n",
        "\n",
        "data_preprocessed = preprocess_data(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK_RQprDmFQd",
        "outputId": "11273ef5-05d6-45f5-9173-1b7e7ced3d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X Tensor shape: torch.Size([10000, 31])\n",
            "y Tensor shape: torch.Size([10000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = data_preprocessed.drop('click', axis=1).values\n",
        "y = data_preprocessed['click'].values\n",
        "\n",
        "X = X.astype('float32')\n",
        "y = y.astype('float32')\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "print(\"X Tensor shape:\", X_tensor.shape)\n",
        "print(\"y Tensor shape:\", y_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s18OskXLv0tY"
      },
      "source": [
        "**______________________________________________________________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDHUwlD7v2Bp"
      },
      "source": [
        "**Task 2: Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_chJzHv2KR"
      },
      "source": [
        "**______________________________________________________________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcPHhbRtv_zd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # Linear layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "input_dim = X_tensor.shape[1]\n",
        "model = LogisticRegressionModel(input_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "learning_rate = 0.15\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    y_pred = model(X_tensor)\n",
        "    loss = criterion(y_pred.squeeze(), y_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_values.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "plt.plot(range(num_epochs), loss_values, color='purple')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Over Time (learning rate 0.01)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBX7RxIMkRiZ"
      },
      "outputs": [],
      "source": [
        "weights = model.linear.weight\n",
        "bias = model.linear.bias\n",
        "alpha = torch.matmul(X_tensor, weights.T) + bias\n",
        "y_scores = torch.sigmoid(alpha)\n",
        "y_scores_unique = torch.unique(y_scores)\n",
        "sorted_scores_unique, _ = torch.sort(y_scores_unique, descending=True)\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "thresholds = []\n",
        "tp, fp = 0, 0\n",
        "total_positives = torch.sum(y_tensor).item()\n",
        "\n",
        "\n",
        "for threshold in sorted_scores_unique:\n",
        "    y_pred = (y_scores >= threshold).float()\n",
        "    tp = ((y_pred == 1) & (y_tensor == 1)).sum().item()\n",
        "    fp = ((y_pred == 1) & (y_tensor == 0)).sum().item()\n",
        "    precision = tp / (tp + fp + 1e-10)\n",
        "    recall = tp / total_positives\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    thresholds.append(threshold.item())\n",
        "\n",
        "\n",
        "precisions = torch.tensor(precisions)\n",
        "recalls = torch.tensor(recalls)\n",
        "plt.plot(recalls.numpy(), precisions.numpy(), marker='.', color='purple')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs Recall Curve (Logistic Regression)')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
